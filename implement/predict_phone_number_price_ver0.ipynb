{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.ExcelFile('crawl_data/train_data.xlsx', encoding= 'utf-8').parse('Sheet1')\n",
    "df_test = pd.ExcelFile('crawl_data/test_data.xlsx', encoding= 'utf-8').parse('Sheet1')\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocesing data\n",
    "def check_mobile_number(phone_number):\n",
    "    '''\n",
    "    input: (str) the mobile number\n",
    "    output: bool\n",
    "    '''\n",
    "    if (len(phone_number) == 9):\n",
    "        #phone_number = str(phone_number)\n",
    "        # các đầu số di động của các nhà mạng ở Việt Nam \n",
    "        dau_so_di_dong = ['89', '90', '93', '70', '79', '77', '76', '78', '96', '97', '98', '86', '32', \n",
    "                      '33', '34', '35', '36', '37', '38', '39', '88', '91', '94', '81', '82', '83', \n",
    "                      '84', '85', '92', '56', '58', '99', '19', '52', '59', '87', '95', '71', '72', '74', '75']\n",
    "        if phone_number[:2] in dau_so_di_dong:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "df_train['check'] = df_train.phone_number.astype('str').apply(check_mobile_number)\n",
    "df_test['check'] = df_test.phone_number.astype('str').apply(check_mobile_number)\n",
    "\n",
    "# clean data\n",
    "df_test = df_test[df_test.check == 1]\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.drop(['index', 'id_phone_test', 'check'], axis= 1)\n",
    "df_test = df_test.reset_index()\n",
    "df_test.columns = ['id_test_p', 'price', 'phone_number', 'target']\n",
    "\n",
    "\n",
    "df_train = df_train[df_train.check == 1]\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.drop(['index', 'id_phone_train', 'check'], axis= 1)\n",
    "df_train = df_train.reset_index()\n",
    "df_train.columns = ['id_train_p', 'price', 'phone_number', 'target']\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# triggram\n",
    "# triggram = ['0'+i for i in biggram] + [str(i) for i in list(np.arange(100,1000))]\n",
    "# df_triggram = pd.DataFrame()\n",
    "# df_triggram['num_phrases'] = triggram\n",
    "# df_triggram = df_triggram.reset_index()\n",
    "# df_triggram.columns = ['id', 'num_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-gram\n",
    "def generate_ngrams(text, n_gram= 2):\n",
    "    text = str(text)\n",
    "    token = [str(i) for i in text]\n",
    "    #print(token)\n",
    "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
    "    #print(ngrams)\n",
    "    ngrams1 = \"|\".join([\" \".join(ngram) for ngram in ngrams])\n",
    "    ngrams1 = re.sub('\\s+', '', ngrams1)\n",
    "    return ngrams1.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create sparse matrix\n",
    "def create_sparse_mt(x_values, x_u, x_i, n_row, n_col):\n",
    "    return sparse.csr_matrix((x_values,(x_u,x_i)),(n_row,n_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the index for the num_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     22,
     29
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create index for the num_phrases\n",
    "# bộ 6 số cuối đẹp \n",
    "luc = [str(i)*6 for i in range(0,10)]\n",
    "tang_dan_6 = generate_ngrams('0123456789', n_gram= 6).split('|')\n",
    "lap_6 = ['ABABAB']\n",
    "\n",
    "# bộ 5 số cuối đẹp \n",
    "ngu = [str(i)*5 for i in range(0,10)]\n",
    "tang_dan_5 = generate_ngrams('0123456789', n_gram= 5).split('|')\n",
    "ganh_5 = ['ABCAB']\n",
    "\n",
    "# bộ 4 số cuối đẹp \n",
    "tu = [str(i)*4 for i in range(0,10)]\n",
    "tang_dan_4 = generate_ngrams('0123456789', n_gram= 4).split('|')\n",
    "lap_4 = ['ABAB']\n",
    "\n",
    "# bộ 3 số cuối đẹp\n",
    "tam = [str(i)*3 for i in range(0,10)]\n",
    "tang_dan_3 = generate_ngrams('0123456789', n_gram= 3).split('|')\n",
    "ganh_3 = ['ABA']\n",
    "\n",
    "# bộ 2 số cuối đẹp \n",
    "nhi = ['06', '09', '10', '12', '16', '17', '18', '19', '26', '28', '33',\n",
    "   '36', '37', '38', '39', '40', '40', '46', '50', '52', '53', '56',\n",
    "   '57', '66', '66', '68', '77', '78', '79', '80', '80', '83', '86',\n",
    "   '86', '88', '89', '90', '92', '97']\n",
    "nhi = [i + 'z' for i in nhi]\n",
    "\n",
    "# bộ đầu số các nhà mạng\n",
    "dau_so = ['89', '90', '93', '70', '79', '77', '76', '78', '96', '97', '98', '86', '32', \n",
    "                  '33', '34', '35', '36', '37', '38', '39', '88', '91', '94', '81', '82', '83', \n",
    "                  '84', '85', '92', '56', '58', '99', '19', '52', '59', '87', '95', '71', '72', '74', '75']\n",
    "dau_so = [i+'a' for i in dau_so]\n",
    "\n",
    "# biggram\n",
    "biggram = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09'] + [str(i) for i in list(np.arange(10,100))]\n",
    "\n",
    "num_phrases = dau_so + biggram + nhi + luc + tang_dan_6 + lap_6 + ngu + tang_dan_5 + ganh_5 + tu + tang_dan_4 + lap_4 + tam + tang_dan_3 + ganh_3\n",
    "df_num = pd.DataFrame()\n",
    "df_num['num_phrases'] = num_phrases\n",
    "df_num_phrases = df_num.reset_index()\n",
    "df_num_phrases.columns = ['id', 'num_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('index_num_phrases_ver3.xlsx', engine='xlsxwriter')\n",
    "# df_num_phrases.to_excel(writer, 'Sheet1', index= False, encoding= 'utf-8')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     5,
     7,
     10,
     30,
     34,
     38,
     41,
     44,
     47,
     52,
     54,
     59,
     64,
     69,
     71,
     76,
     81,
     86,
     88,
     93,
     98,
     102,
     104,
     109,
     114
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract feature\n",
    "def extract_feature(idx, phone_number):\n",
    "    '''\n",
    "    input: (str) phone number\n",
    "    '''\n",
    "    if phone_number[0] == '0':\n",
    "            phone= phone_number[1:]\n",
    "    else:\n",
    "        phone = phone_number\n",
    "    # kiểm tra số điện thoại\n",
    "    if check_mobile_number(phone)== 0:\n",
    "        return 0\n",
    "    \n",
    "     \n",
    "    # create a DataFrame, contain the each mobile number infor\n",
    "    df = pd.DataFrame()\n",
    "    # thực hiện biggram cho 7 số cuối của chuỗi số điện thoại \n",
    "    df['num_phrases'] = generate_ngrams(phone[2:], n_gram= 2).split('|')\n",
    "    df = df.num_phrases.value_counts().to_frame()\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['num_phrases', 'count']\n",
    "    \n",
    "    # xét 2 số đầu tiên của dãy số điện thoại \n",
    "    \n",
    "    so_dau = {'num_phrases':phone[:2]+'a', 'count': 5}\n",
    "    # insert new row into dataframe \n",
    "    df = df.append(so_dau, ignore_index= True)\n",
    "    \n",
    "    # xét 2 số cuối của dãy số điện thoại(trường hợp riêng xét độc lập với trường hợp các bộ số đặc biệt)\n",
    "    # bộ 2 số cuối đẹp \n",
    "    hai_so_cuoi  = ['06', '09', '10', '12', '16', '17', '18', '19', '26', '28', '33',\n",
    "       '36', '37', '38', '39', '40', '40', '46', '50', '52', '53', '56',\n",
    "       '57', '66', '66', '68', '77', '78', '79', '80', '80', '83', '86',\n",
    "       '86', '88', '89', '90', '92', '97']\n",
    "    if phone[-2:] in hai_so_cuoi:\n",
    "        so_cuoi_2 = {'num_phrases': phone[-2:]+'z', 'count': 3}\n",
    "        df = df.append(so_cuoi_2, ignore_index= True)\n",
    "    \n",
    "    # xét các bộ số đặc biệt trong chuỗi 7 số cuối \n",
    "        # bộ 6 số cuối đẹp \n",
    "    luc = [str(i)*6 for i in range(0,10)]\n",
    "    tang_dan_6 = generate_ngrams('0123456789', n_gram= 6).split('|')\n",
    "        # bộ 5 số cuối đẹp \n",
    "    ngu = [str(i)*5 for i in range(0,10)]\n",
    "    tang_dan_5 = generate_ngrams('0123456789', n_gram= 5).split('|')\n",
    "        # bộ 4 số cuối đẹp \n",
    "    tu = [str(i)*4 for i in range(0,10)]\n",
    "    tang_dan_4 = generate_ngrams('0123456789', n_gram= 4).split('|')\n",
    "        # bộ 3 số cuối đẹp\n",
    "    tam = [str(i)*3 for i in range(0,10)]\n",
    "    tang_dan_3 = generate_ngrams('0123456789', n_gram= 3).split('|')\n",
    "    \n",
    "    # bộ 6 số \n",
    "        # nếu 6 số cuối là bộ số luc: 000000, ..., 999999\n",
    "    if phone[-6:] in luc:\n",
    "        so_cuoi = {'num_phrases': phone[-6:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # 012345, ..., 456789\n",
    "    elif phone[-6:] in tang_dan_6:\n",
    "        so_cuoi = {'num_phrases': phone[-6:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # cac bo so lap 6: ABABAB\n",
    "    elif (phone[-6:-4] == phone[-4:-2]) and (phone[-6:-4] == phone[-2:]):\n",
    "        so_cuoi = {'num_phrases': 'ABABAB', 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        \n",
    "    # bộ 5 số cuối \n",
    "        # nếu 5 số cuối là bộ số luc: 00000, ..., 99999\n",
    "    elif phone[-5:] in ngu:\n",
    "        so_cuoi = {'num_phrases': phone[-5:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # 01234, ..., 56789\n",
    "    elif phone[-5:] in tang_dan_5:\n",
    "        so_cuoi = {'num_phrases': phone[-5:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # cac bo so ganh 5: ABCAB\n",
    "    elif (phone[-5:-3] == phone[-2:]):\n",
    "        so_cuoi = {'num_phrases': 'ABCAB', 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        \n",
    "    # bộ 4 số cuối \n",
    "         # nếu 4 số cuối là bộ số 4 chữ số: 0000, ..., 999\n",
    "    elif phone[-4:] in tu:\n",
    "        so_cuoi = {'num_phrases': phone[-4:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # 01234, ..., 56789\n",
    "    elif phone[-4:] in tang_dan_4:\n",
    "        so_cuoi = {'num_phrases': phone[-4:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # cac bo so lap 4: ABAB\n",
    "    elif (phone[-4:-2] == phone[-2:]):\n",
    "        so_cuoi = {'num_phrases': 'ABAB', 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "    \n",
    "    # bộ 3 số cuối \n",
    "        # nếu 3 số cuối là bộ số luc: 000, ..., 999\n",
    "    elif phone[-3:] in tam:\n",
    "        so_cuoi = {'num_phrases': phone[-3:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # 012, ..., 789\n",
    "    elif phone[-3:] in tang_dan_3:\n",
    "        so_cuoi = {'num_phrases': phone[-3:], 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "        # cac bo so ganh 5: ABCAB\n",
    "    elif (phone[-3] == phone[-1]):\n",
    "        so_cuoi = {'num_phrases': 'ABA', 'count': 5}\n",
    "        df = df.append(so_cuoi, ignore_index= True)\n",
    "\n",
    "    df['id'] = idx\n",
    "    df = df[['id', 'num_phrases', 'count']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "extract_feature(0, '0399946756')\n",
    "t2 = time.time()\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_data_train = []\n",
    "for i in range(df_train.shape[0]):\n",
    "    ls_data_train.append(extract_feature(int(df_train.loc[i, 'id_train_p']), str(df_train.loc[i, 'phone_number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_data_test = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_data_test.append(extract_feature(int(df_test.loc[i, 'id_test_p']), str(df_test.loc[i, 'phone_number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_train = pd.concat(ls_data_train, axis = 0)\n",
    "df_feature_test = pd.concat(ls_data_test, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_train = df_feature_train.reset_index()\n",
    "df_feature_train = df_feature_train.drop('index', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_test = df_feature_train.reset_index()\n",
    "df_feature_test = df_feature_test.drop('index', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_num_phrases['num_phrases'] = df_num_phrases.num_phrases.astype('str')\n",
    "df_feature_test.num_phrases = df_feature_test.num_phrases.astype('str')\n",
    "df_feature_train.num_phrases = df_feature_train.num_phrases.astype('str')\n",
    "# merge index of the biggram and triggram phrases\n",
    "df_feature_test = pd.merge(df_feature_test, df_num_phrases, on= 'num_phrases', how= 'left')\n",
    "df_feature_train = pd.merge(df_feature_train, df_num_phrases, on= 'num_phrases', how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(df_feature_train.shape[0]):\n",
    "#     print('index: ',i)\n",
    "#     print(int(df_feature_train.loc[i, 'id_num']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_test = df_feature_test[['id_x', 'id_y', 'count', 'num_phrases']]\n",
    "df_feature_test['id_x'] = df_feature_test['id_x'].astype('int')\n",
    "df_feature_test.id_y = df_feature_test.id_y.astype('int')\n",
    "df_feature_test.columns = ['id', 'id_num', 'count', 'num_phrases']\n",
    "\n",
    "df_feature_train = df_feature_train[['id_x', 'id_y', 'count', 'num_phrases']]\n",
    "df_feature_train['id_x'] = df_feature_train['id_x'].astype('int')\n",
    "df_feature_train.id_y = df_feature_train.id_y.astype(int)\n",
    "df_feature_train.columns = ['id', 'id_num', 'count', 'num_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('feature_train.xlsx', engine='xlsxwriter')\n",
    "# df_feature_train[['id', 'id_num', 'count']].to_excel(writer, 'Sheet1')\n",
    "# writer.save()\n",
    "\n",
    "# writer1 = pd.ExcelWriter('feature_test.xlsx', engine='xlsxwriter')\n",
    "# df_feature_test[['id', 'id_num', 'count']].to_excel(writer1, 'Sheet1')\n",
    "# writer1.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train = df_feature_train[['id', 'id_num', 'count']].as_matrix()\n",
    "feature_test = df_feature_test[['id', 'id_num', 'count']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_row_train = max(df_feature_train['id']) + 1\n",
    "n_row_test = max(df_feature_test['id']) + 1\n",
    "n_col = max(df_feature_train['id_num']) + 1\n",
    "print(n_row_train)\n",
    "print(n_row_test)\n",
    "print(n_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_csr = sparse.csr_matrix((feature_train[:, 2],(feature_train[:,0],feature_train[:,1])),(n_row_train,n_col))\n",
    "X_test_sparse_csr = sparse.csr_matrix((feature_test[:, 2], (feature_test[:, 0], feature_test[:, 1])),(n_row_test, n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('X_train_sparse_csr_ver1.pkl','wb') as f:\n",
    "#     pickle.dump(X_train_sparse_csr,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Similar( Y_chall_sparse_csr, Y_train_sparse_csr):\n",
    "    # cosine ( (i x u1).T . ( i x u2).T ) = u1 x u2 : uuCF\n",
    "    # using cosine compute similarity between challenge_set ( 118553x1100) and training_set ( 474208x1100)\n",
    "    \n",
    "    S = cosine_similarity(Y_chall_sparse_csr,Y_train_sparse_csr) # (118553 x 474208)\n",
    "    return S # 118553 x 474208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = Similar(X_test_sparse_csr[0], X_train_sparse_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_price(id_phone,  Similar, k1):\n",
    "    # tính độ đương đồng của id_phone với tất cả các id trong tập train\n",
    "    # vector giá trị tương đồng \n",
    "    similar_vec = Similar(X_test_sparse_csr[id_phone], X_train_sparse_csr)\n",
    "    # lấy k1 id trong tập training có độ tương đồng lớn nhất với id_phone\n",
    "    # take k1 user the most similarity with user : u_id\n",
    "    k1_u_similar = np.argsort(similar_vec[0])[-k1: ]\n",
    "    \n",
    "    # từ k1 id trong tập train tương đồng này ta tính giá tiền trung bình của các id này\n",
    "    pred_price = np.mean(df_train[df_train.id_train_p.isin(k1_u_similar)].price.values)\n",
    "    \n",
    "    # tạo bảng dữ liệu chứa thông tin số điện thoại được dự đoán giá tiền\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = [id_phone]\n",
    "    df['phone_number'] = [df_test.loc[id_phone, 'phone_number']]\n",
    "    df['price_ori'] = [df_test.loc[id_phone, 'price']]\n",
    "    df['price_predict'] = [pred_price]\n",
    "    del similar_vec\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = predict_price(1, Similar, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.loc[0, 'price_predict']/d.loc[0, 'price_ori']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ratio):\n",
    "    if (ratio >= 0.9) & (ratio <= 1.1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def evualuation(ls_pred):\n",
    "    df_pred = pd.concat(ls_pred, axis= 0)\n",
    "    df_pred['ratio'] = df_pred.price_predict/df_pred.price_ori\n",
    "    df_pred['acc'] = df_pred.ratio.apply(accuracy)\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "23507/df_p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls_pred = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    ls_pred.append(predict_price(i, Similar, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_p = evualuation(ls_pred)\n",
    "df_p.acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
